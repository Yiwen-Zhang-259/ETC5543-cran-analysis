# Results

## Daily download of R-packages

```{r vars-pkg-downloads, cache = TRUE}
dd_start <- "2012-10-01"
dd_end <- Sys.Date() - 2

is_weekend <- function(date) {
  weekdays(date) %in% c("Saturday", "Sunday")
}

total_downloads <- cran_downloads(from = dd_start, to = dd_end) %>% 
  mutate(year = year(date),
         day = yday(date),
         weekend = is_weekend(date)) 
```


```{block, type="discovery", echo = TRUE}
**Finding 1**: There was unusual download activity in one day of 2014 and 2018. 
```

In this first section, we studied the daily downloads of CRAN packages from `r dd_start` to `r dd_end`. The data was obtained from the `cranlogs` package[@cranlogs], which includes a summary of the download logs from the RStudio CRAN mirror. The daily download data for CRAN packages are available from 1st October 2012. Examination of this data showed two unusual observations in 2014 and 2018 as shown in Figure \@ref(fig:unusual-spikes). The one happening in 2014 was on 2014-11-17, which was Monday, while the other one happening in 2018 was on 2018-10-21, which was on Sunday.


(ref:unusual-spikes) Unusual download spikes on 2014 and 2018. 

```{r unusual-spikes, fig.cap="(ref:unusual-spikes)",cache = TRUE}
plot_daily <- total_downloads %>% 
  group_by(year) %>% 
  mutate(max_count = max(count)) %>% 
  ungroup() %>% 
  filter(year %in% c(2014, 2018)) %>% 
  ggplot(aes(x = day, y = count/1e6)) +
  geom_area(aes(y = weekend * max_count/1e6),
            fill="#e3e3e3")+
  geom_line() +
  labs(x = "Day",
       y = 'Download count (in millions)',
       title = "Daily download for 2014 and 2018") +
  facet_grid(facets = year ~ ., 
             scales = "free_y") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
  plot.title = element_text(h = 0.5))

plot_daily
```


```{r unusual-spike}
#daily_download_20141117 <- read_csv("data/2014-11-17.csv")
#daily_download_20181021 <- read_csv("data/2018-10-21.csv")

#save(daily_download_20141117, file=here::here("data/daily_download_20141117.rda"))
#save(daily_download_20181021, file=here::here("data/daily_download_20181021.rda"))

load("data/daily_download_20141117.rda")
load("data/daily_download_20181021.rda")
```

Then let's have a closer look into these two spikes. First, we focused on the spike on 2014-11-17. From Table \@ref(tab:spike14count), we could see that the downloads between top downloaded packages on this day differs little, so it's not due to certain package.

```{r spike14count}
## for 2014-11-17
daily_download_20141117 %>%
  group_by(package) %>%
  count() %>%
  arrange(desc(n))%>% 
  head(10) %>%
  kable(caption = "The total downloads of each package on 2014-11-17") %>%
  kable_styling(full_width = FALSE)
```

Table \@ref(tab:spike14country) shows the downloads from different countries. It is obvious that downloads from Indonesia is much more than any others, which indicates the most downloads are from Indonesia.

```{r spike14country}
daily_download_20141117 %>%
  group_by(country) %>%
  count() %>%
  arrange(desc(n))%>% 
  head(10) %>%
  kable(caption = "The countries downloading from CRAN on 2014-11-17") %>%
  kable_styling(full_width = FALSE) #downloads from Indonesia is much more than any others
```

Furthermore, we also checked the IP address in Table \@ref(tab:spike14ip), downloads from `ip3758` is much higher than others. So, it seems that most of the downloads were owing to one certain IP. 

```{r spike14ip}
daily_download_20141117 %>%
  group_by(ip_id) %>%
  count() %>%
  arrange(desc(n))%>% 
  head(10) %>%
  kable(caption = "The IP address downloading from CRAN on 2014-11-17") %>%
  kable_styling(full_width = FALSE) #downloads from ip3758 is much higher than others

```

Next, let's turn to the one in 2018. Table \@ref(tab:spike18count) shows the downloads from tidyverse is much higher than others with nearly three orders of magnitude. 

```{r spike18count}
## for 2018-10-21
daily_download_20181021 %>%
  group_by(package) %>%
  count() %>%
  arrange(desc(n))%>% 
  head(10) %>%
  kable(caption = "The total downloads of each package on 2014-11-17") %>%
  kable_styling(full_width = FALSE) 

```

As for the country, from Table \@ref(tab:spike18country) we could know that US is much higher than any other country.

```{r spike18country}
daily_download_20181021 %>%
  group_by(country) %>%
  count() %>%
  arrange(desc(n))%>% 
  head(10) %>%
  kable(caption = "The countries downloading from CRAN on 2014-11-17") %>%
  kable_styling(full_width = FALSE) 

```

Finally, the most interesting finding is in IP address displayed in Table \@ref(tab:spike18ip). Several consecutive IP has highly distinguished downloads. It seems that they are from same person, or it is also probably a test server issue in the same short period of time.

```{r spike18ip}
daily_download_20181021 %>%
  group_by(ip_id) %>%
  count() %>%
  arrange(desc(n))%>% 
  head(10) %>%
  kable(caption = "The IP address downloading from CRAN on 2014-11-17") %>%
  kable_styling(full_width = FALSE) #several ip has highly distiguished downloads and they are contiguous. It seems that they are from same person, and it is also probably that it's a server issue.

```

Therefore, to sum up, we found that these two unusual spikes have one thing in common, that is, most of the downloads came from a specific country. The difference is that in 2014, a large number of downloads came from several different packages, while in 2018, they came from one package `tidyverse`. In addition, in 2014, a large number of downloads came from one IP, while in 2018, they came from several consecutive IPs, At this point, we guess it should come from the same person, and it is likely to be sever issue, for it may be not necessary and reasonable for an individual to generate such a high amount of downloads in one day.

```{block, type="discovery", echo = TRUE}
**Finding 2**: There is an increasing number of downloads over time. This likely attests to the growing number of R users. 
```

Figure \@ref(fig:download-over-time) shows the download trend of all packages on CRAN over time after fixing the unusual spikes. It shows an upward trend over time, and the variance also increases with the download count, which means the volatility of the data is increasing.

(ref:download-over-time) The download trend of all packages on CRAN over time. 

```{r download-over-time, fig.cap="(ref:download-over-time)"}
total_downloads_fix <- total_downloads %>% 
  mutate(count = ifelse(count > 3e6 & year==2014 | count > 10e6 & year==2018, 
                        NA, count)) %>% #remove the unusual observations in 2014 and 2018
  group_by(year) %>% 
  mutate(max_count = max(count, na.rm = TRUE)) %>% 
  ungroup()

total_downloads_fix %>% 
  ggplot(aes(date, count/1e6)) +
  geom_line(colour="gray") +
  labs(x = "Date", y = "Download count (in millions)",title = "Daily download count of total packages")
```

```{block, type="discovery", echo = TRUE}
**Finding 3**: Weekends have a lower download than weekdays.
```

To have a closer look at the weekly pattern, figure \@ref(fig:total-trend) shows the daily downloads of all CRAN packages from the RStudio mirror with the grey areas highlighting the weekend. 

To be more specific, we could know that except for 2012 and 2013, the patterns of other years are very similar, that is, they all show strong weekly seasonality. To be more detailed, in 2012, the download logs showed an overall upward trend, because more and more users began to download packages from CRAN after its open. In the following years, there is no obvious trend in download volume, but a strong seasonality, which indicates that in a week, the total downloads always increases first then decreases, and reaches the lowest at the weekend. Although the pattern of 2013 is more volatile, it still conforms to that. We think for 2013, that is because CRAN is only open for a short time at this time, and the amount of data downloaded is not adequate to show its download pattern very clearly. Considering this, we could see that after 2016, the pattern of each year is quite consistent, for the total download has been increasing year by year. Back to weekly seasonality, that is because people are more likely to download and use packages in weekdays, and rest on weekends. And that's why the trough of download curve always occurs on weekends. In addition, we could also notice that the lowest downloads across the year are always at the end of December and the beginning of January, probably due to the Christmas and New Year's holidays. What's more, the downloads is on the rise from August to October and from February to April, which covers the start of semester for most universities. 

(ref:total-trend) The figure shows the total downloads of all packages on CRAN would decrease on weekends.

```{r total-trend, fig.cap="(ref:total-trend)", fig.height = 12,cache = TRUE}

plot_daily_fix <- plot_daily +
  labs(title = "Total number of package downloads on CRAN",
       subtitle = glue("from {dd_start} to {dd_end}")) 

plot_daily_fix %+%
   total_downloads_fix
```

As there are many fluctuation in daily download pattern which is due to calendar effect and server issue of CRAN mirror, we then applied a model called STL decomposition explained in @stl, to smooth the curve for all the packages. 

(ref:daily-smoothing) The figure shows the total downloads of all packages on CRAN after smoothing.

```{r pkg-stl, fig.cap="(ref:daily-smoothing)"}
# try to use stl model to smooth the curve
total_download_tsble <- total_downloads_fix %>%
  as_tsibble(index = date)

total_download_tsble[is.na(total_download_tsble)] <- 0

pkg_stl <- total_download_tsble %>%
  model(stl = STL(count))

components(pkg_stl) %>%
  as_tsibble() %>%
  autoplot(count, colour="gray") +
  geom_line(aes(y=trend), colour = "#D55E00") +
  labs(
    y = "Download count",
    title = "Daily download count of total packages"
  ) +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5)
  )

```

And this can be applied to any package to adjust the daily download pattern. In this case, we selected two packages `fable` and `forecast` as an example in Figure \@ref(fig:example-adjust). It can be seen that the pattern is smoother after removing the seasonality and ignorance of extremum possibly caused by repeated downloads, updates and test downloads from the server.


(ref:example-adjust) The figure shows the daily downloads of `fable` and `forecast` on CRAN after smoothing.

```{r example-adjust, fig.cap="(ref:example-adjust)", fig.height = 12}
fable_downloads <- cran_downloads(package = "fable", from = dd_start, to = dd_end) %>% 
  mutate(year = year(date),
         day = yday(date),
         weekend = is_weekend(date)) 

fable_downloads_tsble <- fable_downloads %>%
  as_tsibble(index = date)

fable_downloads_tsble[is.na(fable_downloads_tsble)] <- 0

fable_stl <- fable_downloads_tsble %>%
  model(stl = STL(count))

pa <- components(fable_stl) %>%
  as_tsibble() %>%
  autoplot(count, colour="gray") +
  geom_line(aes(y=trend), colour = "#D55E00") +
  labs(
    y = "Download count",
    title = "Daily download count of 'fable'"
  )+
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5)
  )

forecast_downloads <- cran_downloads(package = "forecast", from = dd_start, to = dd_end) %>% 
  mutate(year = year(date),
         day = yday(date),
         weekend = is_weekend(date)) 

forecast_downloads_tsble <- forecast_downloads %>%
  as_tsibble(index = date)

forecast_downloads_tsble[is.na(forecast_downloads_tsble)] <- 0

forecast_stl <- forecast_downloads_tsble %>%
  model(stl = STL(count))

po <- components(forecast_stl) %>%
  as_tsibble() %>%
  autoplot(count, colour="gray") +
  geom_line(aes(y=trend), colour = "#D55E00") +
  labs(
    y = "Download count",
    title = "Daily download count of 'forecast'"
  )+
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5)
  )

ga <- ggplotGrob(pa)
go <- ggplotGrob(po)
gao <- rbind(ga, go, size = "first")
gao$widths <- unit.pmax(ga$widths, go$widths)
grid.newpage()
grid.draw(gao)
 
```


Figure \@ref(fig:weekend-vs-weekday) shows the distribution and the median of the downloads between weekday and weekends. The distribution of weekdays and weekends are quite different. Weekends are wider and shorter, while weekdays are thinner and higher, because the total download of data on weekends is less than that on weekdays. And in 2012, the median and interquartile range of download logs are not very distinguished between weekdays and weekends, for the data volume was not adequate at this time as mentioned above. But after 2013, the gap between the two becomes more and more obvious, that is, the median downloads of working days is significantly higher than that of weekends, and the overall number of data is also significantly higher than that of weekends as well. But interestingly, the lower adjacent sometimes occurs on weekends, such as in year 2014, 2015, 2018, 2019 and 2021, while sometimes in weekdays, such as in year 2012, 2013, 2016, 2017 and 2020.

```{r weekend-vs-weekday, fig.height = 7}
total_downloads_fix %>% 
  ggplot(aes(weekend, count/1e6)) +
  geom_violin() +
  geom_boxplot(width = 0.1)  +
  labs(color = "Year",
       x = "Weekday or Weekend",
       y = "Download count (in millions)") +
  facet_wrap(~year, scales = "free_y", nrow = 2) +
  scale_x_discrete(labels = c("Day", "End")) 
```


```{block, type="discovery", echo = TRUE}
**Finding 4**: Top 10% downloaded packages share nearly 90% cumulative download count of the whole.
```

From the previous analysis, we could see that the cumulative download count of R packages shows an increasing trend. It would be perfect equality if every package had the same download count â€“ the last 20% downloaded packages would gain 20% of the total download count or the top 60% downloaded packages would get 60% of the total download count. But we know from experience that this is obviously impossible, so here we introduced Lorenz curve[@lorenz] to show the respective number of packages of different download levels (groups defined by quantiles of download count). In this way, we could figure out how many download counts contributed by different downloaded packages.

```{r totalpkg}
#get all the packages from CRAN 
cran_names <- rownames(available:::available_packages(repos = available:::default_cran_repos)) %>%
  as.data.frame() 

colnames(cran_names)[1] <- "package"

#slice into small sample to speed up the execution
cran_names1 <- cran_names %>% 
  slice(1:850) 

cran_names2 <- cran_names %>% 
  slice(851:1701)

cran_names3 <- cran_names %>% 
  slice(1702:2552)

cran_names4 <- cran_names %>% 
  slice(2553:3403)

cran_names5 <- cran_names %>% 
  slice(3404:4254)

cran_names6 <- cran_names %>% 
  slice(4255:5105)

cran_names7 <- cran_names %>% 
  slice(5106:5956)

cran_names8 <- cran_names %>% 
  slice(5957:6807)

cran_names9 <- cran_names %>% 
  slice(6808:7657)

cran_names10 <- cran_names %>% 
  slice(7658:8508)

cran_names11 <- cran_names %>% 
  slice(8509:9359)

cran_names12 <- cran_names %>% 
  slice(9360:10210)

cran_names13 <- cran_names %>% 
  slice(10211:11061)

cran_names14 <- cran_names %>% 
  slice(11062:11912)

cran_names15 <- cran_names %>% 
  slice(11913:12763)

cran_names16 <- cran_names %>% 
  slice(12764:13614)

cran_names17 <- cran_names %>% 
  slice(13615:14465)

cran_names18 <- cran_names %>% 
  slice(14466:15316)

cran_names19 <- cran_names %>% 
  slice(15317:16167)

cran_names20 <- cran_names %>% 
  slice(16168:17018)

cran_names21 <- cran_names %>% 
  slice(17019:length(cran_names$package))

td_start <- "2020-10-01"
td_end <- Sys.Date() - 2

#get total download for slice1
cran_names1 <- map_dfr(cran_names1, ~{
  pkgs <- cran_names1$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names1 <- cran_names1 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice2
cran_names2 <- map_dfr(cran_names2, ~{
  pkgs <- cran_names2$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names2 <- cran_names2 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice3
cran_names3 <- map_dfr(cran_names3, ~{
  pkgs <- cran_names3$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names3 <- cran_names3 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice4
cran_names4 <- map_dfr(cran_names4, ~{
  pkgs <- cran_names4$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names4 <- cran_names4 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice5
cran_names5 <- map_dfr(cran_names5, ~{
  pkgs <- cran_names5$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names5 <- cran_names5 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice6
cran_names6 <- map_dfr(cran_names6, ~{
  pkgs <- cran_names6$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names6 <- cran_names6 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice7
cran_names7 <- map_dfr(cran_names7, ~{
  pkgs <- cran_names7$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names7 <- cran_names7 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice8
cran_names8 <- map_dfr(cran_names8, ~{
  pkgs <- cran_names8$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names8 <- cran_names8 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice9
cran_names9 <- map_dfr(cran_names9, ~{
  pkgs <- cran_names9$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names9 <- cran_names9 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice10
cran_names10 <- map_dfr(cran_names10, ~{
  pkgs <- cran_names10$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names10 <- cran_names10 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice11
cran_names11 <- map_dfr(cran_names11, ~{
  pkgs <- cran_names11$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names11 <- cran_names11 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice12
cran_names12 <- map_dfr(cran_names12, ~{
  pkgs <- cran_names12$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names12 <- cran_names12 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice13
cran_names13 <- map_dfr(cran_names13, ~{
  pkgs <- cran_names13$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names13 <- cran_names13 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice14
cran_names14 <- map_dfr(cran_names14, ~{
  pkgs <- cran_names14$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names14 <- cran_names14 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice15
cran_names15 <- map_dfr(cran_names15, ~{
  pkgs <- cran_names15$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names15 <- cran_names15 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice16
cran_names16 <- map_dfr(cran_names16, ~{
  pkgs <- cran_names16$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names16 <- cran_names16 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice17
cran_names17 <- map_dfr(cran_names17, ~{
  pkgs <- cran_names17$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names17 <- cran_names17 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice18
cran_names18 <- map_dfr(cran_names18, ~{
  pkgs <- cran_names18$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names18 <- cran_names18 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice19
cran_names19 <- map_dfr(cran_names19, ~{
  pkgs <- cran_names19$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names19 <- cran_names19 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice20
cran_names20 <- map_dfr(cran_names20, ~{
  pkgs <- cran_names20$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names20 <- cran_names20 %>%
  group_by(package) %>%
  summarise(total = sum(count))

#get total download for slice21
cran_names21 <- map_dfr(cran_names21, ~{
  pkgs <- cran_names21$package
  
  cran_downloads(pkgs, from = td_start, to = td_end) 
})

cran_names21 <- cran_names21 %>%
  group_by(package) %>%
  summarise(total = sum(count))


cran_names_download <- rbind(cran_names1,cran_names2,cran_names3,cran_names4,cran_names5,cran_names6,cran_names7,cran_names8,cran_names9,cran_names10,cran_names11,cran_names12,cran_names13,cran_names14,cran_names15,cran_names16,cran_names17,cran_names18,cran_names19,cran_names20,cran_names21)
```


Figure \@ref(fig:download-over-time) shows cumulative download count against each downloaded group. It can be seen that most of the download counts come from the top 10% downloaded packages. At the same time, we could also observe that the Gini value is close to 1, which indicates that the download volume among groups is very unbalanced. In fact, the download volume of the top 10% group is extremely distinguished from that of the following groups. It's not hard to understand that this group should contain some packages with high popularity and large quantities of users. For example, if we extracted the first 10 packages of this group in Table \@ref(tab:top10), we could find that they are all quite famous and frequently-used ones.

(ref:lorenz-all) Percentiles of the download count against cumulative download count of packages at or below that percentile.

```{r lorenz-all, fig.cap="(ref:lorenz-all)",cache = TRUE}
lorenz_curve <- ggplot(cran_names_download, aes(total)) +
stat_lorenz() +
geom_abline(linetype = "dashed") +
annotate_ineq(cran_names_download$total)+
theme_bw()+
  labs(
    y = "Cumulative share of download count",
    x = "Download quantile",
    title = "The number of packages occupied by each group",
    subtitle = "based on download count quantile"
  ) +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5)
  )

lorenz_curve
```

```{r top10}
#quantile(cran_names_download$total,probs = seq(0, 1, 0.1)) 
cran_names_download %>%
  filter(total > 24310) %>%
  arrange(desc(total))%>%
  head(10) %>%
  kable(caption = "First 10 packages of top 10% downloaded group") %>%
  kable_styling(full_width = FALSE) 
```

