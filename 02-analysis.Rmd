# Analysis

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,cache = TRUE,message = FALSE,warning = FALSE, error = FALSE)
library(tidyverse)
library(pkgsearch)
library(jsonlite)
library(grid)
library(cranlogs)
library(ctv)
library(lubridate)
library(rvest)
library(htmltools)
#install.packages("jsonlite")
library(jsonlite)
#install.packages("httpuv")
library(httpuv)
#install.packages("httr")
library(httr)
library(ctv)
library(purrr)
library(kableExtra)
library(packageRank)
library(fpp3)
library(slider)
library(stringr)
library(lubridate)
library(plyr)
library(dplyr)
library(rvest)
library(glue)
library(rlist)
library(plotly)
```

## General daily download trend of all packages

First, let's take a look at the daily downloads of all packages on CRAN from 2019-01-01 to 2021-04-01.  Figure \@ref(fig:total-trend) shows the pattern, and the yellow areas highlight the weekend.We could know that there seems to have strong seasonality, which indicates that in a week, the total downloads always increases first then decreases, and reaches the lowest at the weekend. What's more, the downloads is on the rise from August to October and from February to April, which may be due to the start of semester for most universities.

```{r total-trend, fig.align = 'center', fig.cap="Generally, the total downloads of all packages on CRAN would decrease on weekends."}
# Make plots taller
options(repr.plot.width=8, repr.plot.height=50)

# plot the daily download trend of all packages from CRAN
total_download <- cran_downloads(from = "2019-01-01", to = "2021-04-01")

total_download$Year <- format(total_download$date, "%Y")
total_download$Month <- format(total_download$date, "%b")
total_download$Day <- format(total_download$date, "%d")
total_download$MonthDay <- format(total_download$date, "%d-%b")

total_download$weekend <- weekdays(total_download$date) %in% c("Saturday", "Sunday")

total_download$CommonDate <- as.Date(paste0("2000-",format(total_download$date, "%j")), "%Y-%j")

ggplot(total_download,aes( x = CommonDate, y = count)) +
  geom_area(aes(y=weekend*max(count)), fill="yellow")+
  geom_line() +
  geom_smooth(se = F) +
   labs( x = "Date",
      y = 'Download count',
    title = "Total number of package downloads on CRAN",
    subtitle = "from 2019-01-01 to 2021-04-01") +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5),
  ) +
  facet_grid(facets = Year ~ ., scales='free_x', space='free_x') +
  scale_x_date(labels = function(x) format(x, "%d-%b")) 

```

## Daily top 15 downloaded packages 

We all know that some packages are hold by rstudio, or they are developed by some core personnel or related personnel under R, or some prolific developers. Naturally, the number of downloads of these packages will be higher. (explain why??)
And the existence of these packages will make the results biased. Therefore, in order to explore the interesting findings for packages constructed by non-special creators, I have screened out four types of packages, namely:
- Packages maintained by R studio
- Packages created by authors from R core group
- Packages created by authors from R secondary group
- Packages created by R related authors
- Packages created by top 20 prolific maintainers (explain the recource)

Then, I compared the top 15 downloaded packages April 1 from 2013 to 2021 to see how user preferences has been changing. 

```{r readcran}
url <- "http://cran.rstudio.com/web/packages/packages.rds"
db <- readRDS(url(url)) %>% 
as.data.frame() %>%
  rename(package = Package)

#cran2013_04_01 <- read_csv("data/2013-04-01.csv")
#cran2014_04_01 <- read_csv("data/2014-04-01.csv")
#cran2015_04_01 <- read_csv("data/2015-04-01.csv")
#cran2016_04_01 <- read_csv("data/2016-04-01.csv")
#cran2017_04_01 <- read_csv("data/2017-04-01.csv")
#cran2018_04_01 <- read_csv("data/2018-04-01.csv")
#cran2019_04_01 <- read_csv("data/2019-04-01.csv")
#cran2020_04_01 <- read_csv("data/2020-04-01.csv")
#cran2021_04_01 <- read_csv("data/2021-04-01.csv")

#save(cran2013_04_01, file=here::here("data/cran2013_04_01.rda"))
#save(cran2014_04_01, file=here::here("data/cran2014_04_01.rda"))
#save(cran2015_04_01, file=here::here("data/cran2015_04_01.rda"))
#save(cran2016_04_01, file=here::here("data/cran2016_04_01.rda"))
#save(cran2017_04_01, file=here::here("data/cran2017_04_01.rda"))
#save(cran2018_04_01, file=here::here("data/cran2018_04_01.rda"))
#save(cran2019_04_01, file=here::here("data/cran2019_04_01.rda"))
#save(cran2020_04_01, file=here::here("data/cran2020_04_01.rda"))
#save(cran2021_04_01, file=here::here("data/cran2021_04_01.rda"))

load("data/cran2013_04_01.rda")
load("data/cran2014_04_01.rda")
load("data/cran2015_04_01.rda")
load("data/cran2016_04_01.rda")
load("data/cran2017_04_01.rda")
load("data/cran2018_04_01.rda")
load("data/cran2019_04_01.rda")
load("data/cran2020_04_01.rda")
load("data/cran2021_04_01.rda")

```

```{r filter-list}
# filter the packages maintained by R studio
pkg_rstusio <- db %>%
  filter(grepl('RStudio', Author)) %>%
  select(package) 


# filter the packages whose author is from R core group
pkg_core <- db %>%
  filter(grepl('Douglas Bates|John Chambers|Peter Dalgaard|Robert Gentleman|Kurt Hornik|Ross Ihaka|Tomas Kalibera|Michael Lawrence|Friedrich Leisch|Uwe Ligges|Thomas Lumley|Martin Maechler|Martin Morgan|Paul Murrell|Brian Ripley|Deepayan Sarkar|Duncan Temple Lang|Luke Tierney|Simon Urbanek|Martyn Plummer|', Author)) %>%
  select(package)

# filter the packages whose author is on R secondary group
pkg_secondary <- db %>%
  filter(!grepl('Guido Masarotto|Duncan Murdoch|Henrik Bengtsson|Roger Bivand|Ben Bolker|David Brahm|Vince Carey|Saikat DebRoy|Matt Dowle|Dirk Eddelbuettel|Claus Ekstrom|John Fox|Paul Gilbert|Yu Gong|Gabor Grothendieck|Frank E Harrell Jr|Peter M. Haverty|Torsten Hothorn|Robert King|Kjetil Kjernsmo|Roger Koenker|Philippe Lambert|Jan de Leeuw|Jim Lindsey|Patrick Lindsey|Catherine Loader| Gordon Maclean|Arni Magnusson|John Maindonald|David Meyer|Ei-ji Nakama|Jens Oehlschägel|Steve Oncley|Richard O’Keefe|Hubert Palme|Roger D. Peng|José C. Pinheiro|Tony Plate|Anthony Rossini| Jonathan Rougier|Petr Savicky|Günther Sawitzki|Marc Schwartz|Arun Srinivasan|Detlef Steuer|Bill Simpson|Gordon Smyth|Adrian Trapletti|Terry Therneau|Rolf Turner|Bill Venables|Gregory R. Warnes| Andreas Weingessel|Morten Welinder|James Wettenhall|Simon Wood|and Achim Zeileis', Author)) %>%
  select(package) 


# filter the packages developed by top 20 prolific maintainers
pkg_20maintainer <- db %>% 
  filter(stringr::str_detect(Author, 'Hadley Wickham|Yihui Xie|Dirk Eddelbuettel|Jeroen Ooms|Achim Zeileis|Scott Chamberlain|Gabor Csardi|Jeroen Ooms|ORPHANED|Thomas J. Leeper|Bob Rudis|Henrik Bengtsson|Kurt Hornik|Oliver Keyes|Martin Maechler|Richard Cotton|Robin K. S. Hankin|Simon Urbanek|Kirill Muller|Torsten Hothorn|Paul Gilbert') )%>%
  select(package) 


# filter the packages developed by other R studio related authors
pkg_r_related <- db %>%
  filter(stringr::str_detect(Author, 'Hadley Wickham|Yihui Xie|Gabor Csardi|Winston Chang|Andrie de Vries|Alison Presmanes Hill|Mara Averick|Cole Arendt|Daniel Falbel|Garrick Aden-Buie|Garrett Grolemund|Gary|Joe Cheng|Jennifer (Jenny) Bryan|Jim Hester|J.J. Allaire|Jonathan|Joshua Spiewak|Dan Buch|Richard Iannone|Ralf Stubner|Tyler Finethy|Melissa Barca|Kevin Ushey|Javier Luraschi|Karl Feinauer|Charles Teague|Maria Semple|adamconroy|Ricardo Andrade|Steve Nolen|Randy Lai|Jeffrey Horner|Jan Marvin Garbuszus|Justace Clutter|Josh Paulson|Mike Bessuille|Jeffrey Arnold|Paul Kaefer|Jim Hester|Dirk Schumacher|
Philipp A.|Fabian Mundt|Fabian Mundt|boB Rudis|Asher|Henrik Bengtsson|James Lamb|rich-rstudio|Andrie de Vries|Iñaki Ucar|Mark Brown|Hiroaki Yutani|Dean Attali|Matthias Mailänder|Bruno Tremblay|Ian|John Blischak|Chris von Csefalvay|Jeroen Ooms|
Daniel Gromer|Kirill Müller|Jan Gleixner|Alexander Grueneberg|Darío Hereñú|Aron Atkins|harupiko|Barret Schloerke|James Arnold|Giuseppe Casalicchio|Fredric Johansson|Curtis Kephart|reudismam|Jeff Allen|Yuri Niyazov|Sean Kross|Carl A. B. Pearson|
Peter Glerup Ericson|Diomidis Spinellis|Paul Menzel|Lincoln Mullen|Colin Gillespie|Masafumi Okada|Øystein Sørensen|Matthew Grogan|Scott Kostyshak|Marcus Kinsella|rhinopotamus|Daiki Katsuragawa|Michael Steinbaugh|Jari Karppinen|Roy Storey|Kristofer Rye|Erin|Ben Torvaney|Pol Mesalles|Sainath Adapa|Vladimir Panfilov|Christian Brueffer|Julien Barnier|') )%>%
  select(package) 

```


```{r filter-function}
# function used to do filtering
filter_list <- function(pkg){
  
  pkg <- pkg %>%
     filter(!(package %in% pkg_20maintainer$package)) %>%
     filter(!(package %in% pkg_secondary$package)) %>%
     filter(!(package %in% pkg_rstusio$package)) %>%
     filter(!(package %in% pkg_core$package)) %>%
     filter(!(package %in% pkg_r_related$package))
  
  return(pkg)
}
```


```{r filterlist}
# exclude the packages in the above three lists
cran2013_04_01_new <- filter_list(cran2013_04_01)
cran2014_04_01_new <- filter_list(cran2014_04_01)
cran2015_04_01_new <- filter_list(cran2015_04_01)
cran2016_04_01_new <- filter_list(cran2016_04_01)
cran2017_04_01_new <- filter_list(cran2017_04_01)
cran2018_04_01_new <- filter_list(cran2018_04_01)
cran2019_04_01_new <- filter_list(cran2019_04_01)
cran2020_04_01_new <- filter_list(cran2020_04_01)
cran2021_04_01_new <- filter_list(cran2021_04_01)
```


```{r crantop15-1319}
# find the top 30 downloaded packages on 10.1 from 2013 to 2019
cran2013_0401 <- cran2013_04_01_new %>%
  drop_na() %>%
  dplyr::count(package) %>%
  arrange(desc(n)) %>%
  head(15) %>%
  select(package)
  
#cran2013_1001$package <- as.vector(cran2013_1001$package) #get rid of factors

#cran2013_1001$package = factor(cran2013_1001$package,cran2013_1001$package)

cran2014_0401 <- cran2014_04_01_new %>%
  drop_na() %>%
  dplyr::count(package) %>%
  arrange(desc(n)) %>%
  head(15) %>%
  select(package)

cran2015_0401 <- cran2015_04_01_new %>%
  drop_na() %>%
  dplyr::count(package) %>%
  arrange(desc(n)) %>%
  head(15) %>%
  select(package)

cran2016_0401 <- cran2016_04_01_new %>%
  drop_na() %>%
  dplyr::count(package) %>%
  arrange(desc(n)) %>%
  head(15) %>%
  select(package)

cran2017_0401 <- cran2017_04_01_new %>%
  drop_na() %>%
  dplyr::count(package) %>%
  arrange(desc(n)) %>%
  head(15) %>%
  select(package)

cran2018_0401 <- cran2018_04_01_new %>%
  drop_na() %>%
  dplyr::count(package) %>%
  arrange(desc(n)) %>%
  head(15) %>%
  select(package)

cran2019_0401 <- cran2019_04_01_new %>%
  drop_na() %>%
  dplyr::count(package) %>%
  arrange(desc(n)) %>%
  head(15) %>%
  select(package)

cran2020_0401 <- cran2020_04_01_new %>%
  drop_na() %>%
  dplyr::count(package) %>%
  arrange(desc(n)) %>%
  head(15) %>%
  select(package)

cran2021_0401 <- cran2021_04_01_new %>%
  drop_na() %>%
  dplyr::count(package) %>%
  arrange(desc(n)) %>%
  head(15) %>%
  select(package)

```


```{r antijoin-1319}
# find out the new top 15 packages added each year
a <- anti_join(cran2014_0401,cran2013_0401) 
b <- anti_join(cran2015_0401,cran2014_0401) 
c <- anti_join(cran2016_0401,cran2015_0401) 
d <- anti_join(cran2017_0401,cran2016_0401) 
e <- anti_join(cran2018_0401,cran2017_0401) 
f <- anti_join(cran2019_0401,cran2018_0401) 
g <- anti_join(cran2020_0401,cran2019_0401) 
h <- anti_join(cran2021_0401,cran2020_0401) 

# function used to combine data with different length 
cbind_dif <- function(x = list()){
    # Find max length
    max_length <- max(unlist(lapply(x, length)))

    # Set length of each vector as
    res <- lapply(x, function(x){
        length(x) <- max_length
        return(x)
    })

    return(as.data.frame(res))
}

pkg_change <- cbind_dif(list(package14_13 = a$package, package15_14 = b$package, package16_15 = c$package, package17_16 = d$package, package18_17 = e$package, package19_18 = f$package,package20_19 = g$package,package21_20 = h$package))

pkg_change[is.na(pkg_change)] = "-"
```

```{r semijoin-1319}
a1 <- semi_join(cran2014_0401,cran2013_0401)  
b1 <- semi_join(cran2015_0401,cran2014_0401) 
c1 <- semi_join(cran2016_0401,cran2015_0401) 
d1 <- semi_join(cran2017_0401,cran2016_0401) 
e1 <- semi_join(cran2018_0401,cran2017_0401) 
f1 <- semi_join(cran2019_0401,cran2018_0401) 
g1 <- semi_join(cran2020_0401,cran2019_0401) 
h1 <- semi_join(cran2021_0401,cran2020_0401) 

pkg_remain <- cbind_dif(list(package14_13 = a1$package, package15_14 = b1$package, package16_15 = c1$package, package17_16 = d1$package, package18_17 = e1$package, package19_18 = f1$package,package20_19 = g1$package,package21_20 = h1$package))

pkg_remain[is.na(pkg_remain)] = "-"
```

Table \@ref(tab:changed-top15pkg) shows the packages that newly come up to the top 15 list each year, from which we can know what the user preferences increase year by year compared with the previous year. 

```{r changed-top15pkg}
pkg_change %>%
  kable(caption = "Changed top 15 downloaded packages from 2013 to 2019") %>%
  kable_styling(bootstrap_options = c("hover", "striped")) %>%
  scroll_box(width = "100%", height = "400px")

```

Table \@ref(tab:unchanged-top15pkg) shows the packages that remain unchanged each year compared with the previous year, from which we can know which packages are relatively stable in popularity.

```{r  unchanged-top15pkg}
pkg_remain %>%
  kable(caption = "Unchanged top 15 downloaded packages from 2013 to 2019") %>%
  kable_styling(bootstrap_options = c("hover", "striped")) %>%
  scroll_box(width = "100%", height = "400px")
```

```{r}
# to get all the topic names from CRAN task view
task_topic <- available.views(repos = "https://cran.csiro.au/")

topic_name <- task_topic[[1]]$name
x <- lapply(1:length(task_topic),function(i) { topic_name[i] <- task_topic[[i]]$name})

task_topic_all <- list.rbind(x) %>%
  as.data.frame()

colnames(task_topic_all)[1] <- 'topic'


# to get all the packages from CRAN task view along with their topics
pkg_taskview_total = data.frame()

for (i in c(1:length(task_topic_all$topic))) {
  
    topic_pkg <- ctv:::.get_pkgs_from_ctv_or_repos(paste0(task_topic_all$topic[i]), 
                                              repos = "http://cran.rstudio.com/")[[1]]


   df  <- data.frame(matrix(unlist(topic_pkg), nrow=length(topic_pkg), byrow=TRUE),stringsAsFactors=FALSE) %>%
     mutate(topic = paste0(task_topic_all$topic[i]))
   
   colnames(df)[1] <-'packages'
  
   pkg_taskview_total <- rbind(pkg_taskview_total,df)
  
}

colnames(pkg_taskview_total)[1] <- 'package'

# to figure out the classification of packages according to CRAN task view
match_df(pkg_taskview_total,c,on = "package")

```

Let's take a look at the trending packages. Trending packages are packages that downloaded at least 1000 times last week, which have increased significantly compared to the average weekly downloads in the previous 24 weeks[@r-hub]. That is to say, they are packages with high download volume in a recent short time. Through their topic, we can know what areas of packages people are concerned about recently.
As the trending packages are changing through time, let's focus on trending ones before 2021-04-11.

Table \@ref(tab:trending-topic) shows the first 15 trending packages along with their topics.

```{r trending-topic}
# read trending packages before 4.11
pkg_trending <- read_csv("data/pkg_trending.csv") 

pkg_trending_new <- pkg_trending %>%
  select(-score)

pkg_trending_compare <- match_df(pkg_taskview_total,pkg_trending_new,on = "package") %>%
  group_by(topic)

pkg_trending_compare %>%
  head(15) %>%
  kable(caption = "trending packages with topics") %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

And Table \@ref(tab:trending-count) shows the first 10 topics for trending packages. The most popular topic is `TimeSeries`, followed by `Survival` and `WebTechnologies`. This is easy to understand, because the number of people in different fields is different, so there are also differences in the number of packages used in different topics.

```{r trending-count}
pkg_trendcom_count <- pkg_trending_compare %>%
  dplyr::count(topic) %>%
  arrange(desc(n))


pkg_trendcom_count %>%
  head(10) %>%
  kable(caption = "Topics of trending packages") %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

So, apart from the topic of the package itself, what other factors will affect its download volume? With this problem in mind, I mainly explored the relationship between the total number of download counts of packages in the past half a year and the earliest release date, the number of updates, the number of commits on GitHub repositories, the length of the name and the alphabetic order of the first letter of the name.

## Compare last half year's downloads with the earliest release date

In our common cognition, we think that the earlier a package is released, the more people will know about it, and thus the more downloads it will have. However, packages related to different topics cannot be directly compared, because it is possible that the total download amount of packages in a certain topic is higher than that in another topic. Therefore, in order to test this conjecture as clearly as possible, I selected three domain packages through CRAN task view, calculated their respective downloads in the previous half a year, and found their earliest release dates for comparison.


1. Packages for Time Series Analysis

The first topic is Time Series Analysis. Time Series Analysis is a statistical technique that deals with time series data, or trend analysis. Time series data means that data is in a series of  particular time periods or intervals[@timeseries].

```{r get-arcvreleasedate}

# function used to get archive release dates from CRAN
get_arcvupdate_date <- function(packages){
  pkg_url <- "https://cran.r-project.org/web/packages/{pkg}/index.html"
  pkg_archive <- "https://cran.r-project.org/src/contrib/Archive/{pkg}/"
  pkg_updates <- map(packages, function(pkg) {
      
    archive_dates <- tryCatch({ 
        read_html(glue(pkg_archive)) %>% 
          html_table() %>%
          .[[1]] %>% 
          pull(`Last modified`) %>% 
          ymd_hm() %>% 
          na.omit() %>% 
          as.Date()
      }, error = function(e) {
        NULL
      })
    archive_dates
  })
names(pkg_updates) <- packages

updates <- unlist(pkg_updates) %>% 
  enframe("package", "update") %>% 
  # unlist converts date to integers
  mutate(update = as.Date(update, origin = "1970-01-01"),
         # need to get rid of the numbers appended to pkg names
         package = str_extract(package, paste0(packages, collapse="|"))) 

return(updates)
}


```



```{r getpkg}

# function used to get packages of  a certain topic from CRAN task view
get_pkg_taskview <- function(topic_file){

topic_pkg <- ctv:::.get_pkgs_from_ctv_or_repos(paste0(topic_file), 
                                              repos = "http://cran.rstudio.com/")[[1]]


df <- data.frame(matrix(unlist(topic_pkg), nrow=length(topic_pkg), byrow=TRUE),stringsAsFactors=FALSE)

colnames(df)[1] <- 'package'
  
return(df)
}



# get the packages for econometrics
topic_file <- "Econometrics"
Econometrics <- get_pkg_taskview(topic_file) 


# get the packages for time series
topic_file <- "TimeSeries"
TimeSeries <- get_pkg_taskview(topic_file)


# get the packages for bayesian
topic_file <- "Bayesian"
Bayesian <- get_pkg_taskview(topic_file)

```


```{r  function-earliestrelease-counts}
# before use the function 'get_total_downloads', please set the time range
date1 <- "2019-10-01"
date2 <- "2020-04-01"

# function used to get the total downloads of a period of time (date1 to date2) for several packages at the same time
get_total_downloads <- function(packages_vector){
  
total_downloads <- map(packages_vector, function(pkg){
  
  pkg <- cran_downloads(package = paste0(pkg), from = date1, to = date2) %>%
  dplyr::summarise(package = package, count = sum(count)) %>%
  head(1)
  
})
 names(total_downloads) <- packages_vector

downloads <- unlist(total_downloads) %>% 
  enframe("package", "count") %>% 
  mutate(count = suppressWarnings(as.numeric(count)),
         # need to get rid of the numbers appended to pkg names
         package = str_extract(package, paste0(packages_vector, collapse="|")))%>%
         na.omit()
}

# function used to get the total downloads of a period of time and the earliest release date
downloads_earliest_release <- function(packages) {

# function used to get the earliest release date from CRAN
earliest_updates <- function(packages){
  
  earliest_updates <- get_arcvupdate_date(packages) %>%
  dplyr::group_by(package) %>%
  dplyr::arrange(update, .by_group = TRUE) %>% #arrange within group
  top_n(-1, update) # to get the earliest release date, top_n() is used to select the lowest value of a column within each group
  
}

earliest_updates <- earliest_updates(packages)

packages_vector <- earliest_updates$package
  
  
downloads <- get_total_downloads(packages_vector)
  
downloads_release_earliest <- downloads %>%
  as.data.frame() %>%
  left_join(earliest_updates,by = "package")

return(downloads_release_earliest)

}
```



```{r timeseris-updates}
packages <- TimeSeries$package 

timeseries <- downloads_earliest_release(packages) %>%
    arrange(desc(count)) 


timeseries %>%
  head(15) %>%
  kable(caption = "Timeseries packages with earliest release date and last half year's total counts") %>%
  kable_styling(bootstrap_options = c("hover", "striped"))

```
Table \@ref(tab:timeseris-updates) shows the first 15 timeseries packages along with their earliest release date and last half year's total counts. It can be seen that `lubridate` ranks first on download count with release date `r timeseries$update[1]`. Except that, other first four packages are all released before 2010, which is over 10 years ago.

Figure \@ref(fig:timeseries) displays the scatterplot of the last half year's download count and the earliest release date of timeseries packages. It can be seen that generally, as the earliest release date gets later and later, the number of download logs becomes lower and lower. And most of the high downloaded packages are from a period of time between 2004 and 2011. For timeseries packages, they are mainly released between 2012 and 2019. 

```{r timeseries, fig.align = 'center', fig.cap="The older package 'fable' has less download count than that of package 'forecast'."}

timeseries %>%
  ggplot(aes(x = update, y = count)) +
  geom_point() +
  geom_smooth(se = F) +
    labs( x = "Earliest release date",
      y = 'Download count',
    title = "Last half year's downloads with the earliest release date",
    subtitle = "between for time series packages") +
  scale_y_log10() + # to change the scale of y axis
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5))


#timeseries %>%
  #ggplot(aes(update)) +
  #geom_density()

```



2. Bayesian packages for general model fitting

The second topic is Bayesian Inference. Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data[@bayesian].



```{r bayesian-updates}
packages <- Bayesian$package 

bayesian <- downloads_earliest_release(packages) %>%
    arrange(desc(count))

bayesian%>%
  head(15) %>%
  kable(caption = "Bayesian packages with earliest release date and last half year's total counts") %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Table \@ref(tab:bayesian-updates) shows the first 15 econometric packages along with their earliest release date and last half year's total counts. It can be seen that the first-rank package is `r bayesian$package[1]` released on `r bayesian$update[1]`. All the top 3 packages are released before 2005, and all the top 10 packages comes before 2010. 

It can be seen from Figure \@ref(fig:bayesian) that similarly, the earlier packages is released, the more downloads it will have. And most of the packages are from 2007 to 2012.

```{r bayesian,fig.align = 'center', fig.cap="last two years' downloads with the release date for bayesian general model fitting packages."}

bayesian %>%
  ggplot(aes(x = update, y = count)) +
  geom_point() +
  geom_smooth(se = F) +
    labs( x = "Earliest release date",
      y = 'Download count',
    title = "Last half year's downloads with the earliest release date",
    subtitle = "between for bayesian packages") +
  scale_y_log10() + # to change the scale of y axis
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5))




#bayesian %>%
  #ggplot(aes(update)) +
  #geom_density()
```

3. Econometrics 

In order to test whether this is the case in other areas, let's turn our attention to econometrics packages. Econometrics is the use of statistical methods using quantitative data to develop theories or test existing hypotheses in economics or finance, which relies on techniques such as regression models and null hypothesis testing[@econometrics].

```{r eco-updates}
# before use the function 'downloads_earliest_release()', please set the time range
date1 <- "2019-10-01"
date2 <- "2020-04-01"

packages <- Econometrics$package 

econometric <- downloads_earliest_release(packages) %>%
    arrange(desc(count))


econometric %>%
  head(15) %>%
  kable(caption = "Econometrics packages with earliest release date and last half year's total counts") %>%
  kable_styling(bootstrap_options = c("hover", "striped"))

```

Table \@ref(tab:eco-updates) shows the first 15 econometric packages along with their earliest release date and last half year's total counts. It can be seen that the first-rank package is `zoo` released on `r econometric$update[1]`. All the top 3 packages are released before 2005, and all the top 10 packages comes before 2010. 

In Figure \@ref(fig:eco-lm), as we can see, for this kind of package, the download volume decreases more obviously with the release date, which is quite consistent with both timeseries and bayesian situations. And most of the packages are centered between 2013 and 2016.


```{r eco-lm,fig.align = 'center', fig.cap="The latest package sandwich has the highest downloads."}

econometric %>%
  ggplot(aes(x = update, y = count)) +
  geom_point() +
  geom_smooth(se = F) +
    labs( x = "Earliest release date",
      y = 'Download count',
    title = "Last half year's downloads with the earliest release date",
    subtitle = "between for econometrics packages") +
  scale_y_log10()+ # to change the scale of y axis
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5))





#econometric %>%
 # ggplot(aes(update)) +
  #geom_density()
```

In conclusion, I'm not surprised to find that the earlier the package is released, the more downloads it will has, which is reflected in bayesian, econometrics, time series  cases. That is because,t he packages released earlier will be better known. When they are released early, there may be a relatively small number of packages of the same type, so the competition is relatively small. In contrast, the packages released later can easily be covered up, because people tend to use the well-known, mature and habitual packages.

## compare packages with similar release date

I would like to compare packages released on the same date (i.e. April 1st, 2021), so I compare the daily downloads of these packages for 04-02.

By looking into Figure \@ref(fig:pkg0401), we could know that the most downloaded package released on 04-01 is `datetimeutils`, and the second one is `berryFunctions`.

```{r}

```


## Compare moving average of fable and forecast

Let's have a look at package `fable` and `forecast`. They are two closely related packages, for `fable` is the recently released tidy version of `forecast`. Figure \@ref(fig:daily-fbl) and Figure \@ref(fig:daily-fcst) shows the daily download count changing during last half year, which shows strong weekly seasonality. And that means the downloads tend to be higher in week days and thus lower on weekends.  


```{r trans-ff}
# transform the daily download of 'fable' to time series table
fable <- cran_downloads(package = "fable",from = date1, to = date2)
forecast <- cran_downloads(package = "forecast",from = date1, to = date2)

fable <- fable %>%
  as_tsibble(index = date) 

forecast <- forecast %>%
  as_tsibble(index = date) 
```

```{r daily-fbl, fig.align = 'center', fig.cap="Fable's daily downloads shows a seasonal pattern."}
fable %>%
  autoplot(count) +
   labs( y = 'Daily download count',
          x = 'Date',
    title = "The daily downloads of fable",
    subtitle = "from 2019-10-01 to 2021-04-02") +
  scale_y_sqrt() +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5)) 
  
```


```{r  daily-fcst, fig.align = 'center', fig.cap="Fable's daily downloads shows a seasonal pattern."}
forecast %>%
  autoplot(count) +
   labs(  y = 'Daily download count',
          x = 'Date',
    title = "The daily downloads of forecast",
    subtitle = "from 2019-10-01 to 2021-04-02") +
  scale_y_sqrt() +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5)) 

```

Therefore, in order to estimate the trend-cycle and reduce the weekly seasonality to see the changes more clearly, I consider the equal weighed 7 moving average. That is, it calculates the weighted average for every seven consecutive time series with the following weights : [1/7,1/7,1/7,1/7,1/7,1/7,1/7]. 

Figure \@ref(fig:ff-ma) shows the moving average (MA) of `fable` and `forecast` respectively. They have quite different moving average patterns with `forecast`'s download volume much higher than `fable`'s. That is, the MA of `forecast` is relatively stable than that of `fable` except for the time around New Year's Eve when `forecast` has a significant drop. But during that time, a drop also appears in `fable`, which is probably due to the big New Year holiday. In addition, the purple vertical dashed line in plot of `fable` marks the update day of it which is on 2021-1-29. And on that day, its downloads peaked, which is because the number of download counts will increase on the update day.

```{r ff-ma, fig.align = 'center', fig.cap="fable grew significantly before March 1."}
# use 7 MA can get a equal weighed 7 MA 
fable_ma <- fable %>%
  mutate(
    `7-MA` = slider::slide_dbl(count, mean,
                .before = 3, .after = 3, .complete = TRUE)
    )

colors <- c('fable' = '#D55E00', 'forecast' = 'violetred4')

p_fbl <- fable_ma %>%
  autoplot(count, color = "gray") +
  geom_line(aes(y = `7-MA`,colour = 'fable')) +
  geom_vline(xintercept = as.numeric(ymd("2020-01-29")), linetype="dashed", #to get geom_vline to an x-axis of class date
                color = "violetred4", size=0.8) +
  labs( 
  title = "Weighed moving average of fable and forecast",
  subtitle = "from 2021-02-06 to 2021-04-02") +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title.x=element_blank(),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5)) 



forecast_ma <- forecast %>%
  mutate(
    `7-MA` = slider::slide_dbl(count, mean,
                .before = 3, .after = 3, .complete = TRUE)
    )

p_fcst <- forecast_ma %>%
  autoplot(count, color = "gray") +
  geom_line(aes(y = `7-MA`,colour = 'forecast')) +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold")) 


g_fbl <- ggplotGrob(p_fbl)
g_fcst <- ggplotGrob(p_fcst)
gff <- rbind(g_fbl, g_fcst, size = "first")
gff$widths <- unit.pmax(g_fbl$widths, g_fcst$widths)
grid.newpage()
grid.draw(gff)

```



## compare download counts with the number of commits on master branch

In this part, I would like to compare last half year's total downloads with the number of commits on master branch in Github repositories. Let's look back to trending packages.

Table \@ref(tab:pct-lowupdates) shows the top 30 trending packages these days. 

```{r trending-commits}
# to find the 100 trending packages before 4.11 and save as csv file

#pkg_trending <- cran_trending() 

#write_csv(pkg_trending,"data/pkg_trending.csv")

# read top 49 trending packages


pkg_trending_49 <- pkg_trending %>%
  head(49)
 

# exclude the package that only have read-only mirror of the CRAN github repo, and the remaining are 30
pkg_trending_filter <- pkg_trending_49 %>%
  filter(!(package == "proxy")) %>%
  filter(!(package == "uplift")) %>%
  filter(!(package == "spatstat.geom")) %>%
  filter(!(package == "ClickClust")) %>%
  filter(!(package == "gRc")) %>%
  filter(!(package == "anesrake")) %>%
  filter(!(package == "svd")) %>%
  filter(!(package == "textutils")) %>%
  filter(!(package == "rgl")) %>%
  filter(!(package == "tseries")) %>%
  filter(!(package == "tsDyn")) %>%
  filter(!(package == "tseriesChaos")) %>%
  filter(!(package == "penalized")) %>%
  filter(!(package == "mapdata")) %>%
  filter(!(package == "plot3D")) %>%
  filter(!(package == "ic.infer")) %>%
  filter(!(package == "misc3d")) %>%
  filter(!(package == "textshaping")) %>%
  filter(!(package == "ragg"))

```

```{r function-commits}

# function used to extract commits on master branch on Github
get_commits <- function(username,pkg){

pkg_url <- GET(glue::glue("https://api.github.com/repos/{username}/{pkg}/commits?per_page=1"))

# function used to extract commits from github page
commits <-  function(pkg_url) {
  
headers(pkg_url)$link

c <- str_split(headers(pkg_url)$link, ",") %>%
  unlist()


d <- c[str_detect(c,'rel=\"last\"')] 


f <- str_sub(d, str_locate(d, '&page=')[2]+1, str_locate(d, '>')[1]-1)

  return(f)
}
  commits(pkg_url)
 
}

```



```{r  trending-commits1}

commits <- c(get_commits("rtdists","fddm"),get_commits("r-lib","webfakes"),get_commits("nalzok","tree.interpreter"),get_commits("harryprince","geospark"),get_commits("cloudyr","AzureStor"),get_commits("spatstat","spatstat.core"),get_commits("Azure","AzureRMR"),get_commits("baddstats","spatstat.linnet"),get_commits("cran","clickstream"),get_commits("jeroen","js"),get_commits("spatstat","spatstat.sparse"),get_commits("ltorgo","DMwR2"),get_commits("daroczig","botor"),get_commits("timelyportfolio","sunburstR"),get_commits("jacob-long","panelr"),get_commits("markmfredrickson","RItools"),get_commits("DyfanJones","RAthena"),get_commits("jeroen","V8"),get_commits("timelyportfolio","d3r"),get_commits("daroczig","logger"),get_commits("dreamRs","fresh"),get_commits("nir0s","distro"),get_commits("h2oai","rsparkling"),get_commits("christophergandrud","DataCombine"),get_commits("quanteda","quanteda.textmodels"),get_commits("rstudio","bslib"),get_commits("rstudio","jquerylib"),get_commits("mclements","rstpm2"),get_commits("KlausVigo","phangorn"),get_commits("rstudio","sass"))



pkg_trending_commits <- cbind(pkg_trending_filter,commits) %>%
  select(-score)

# set the time range again (last half year)
date1 <- "2019-10-01"
date2 <- "2020-04-01"

# get last half year's total download for each package
trending_downloads <- get_total_downloads(pkg_trending_filter$package) 
  
 #combine the trending commits and trending downloads 
trending_downloads <- left_join(trending_downloads,pkg_trending_commits, by = "package")      

```


```{r commits-tbl}
trending_downloads <- trending_downloads %>%
  arrange(desc(count)) 

trending_downloads %>%
  kable(caption = "Top 30 scored trending packages with commits on Github and last half year's downloads") %>%
  kable_styling(bootstrap_options = c("hover", "striped")) 
```


And Table \@ref(tab:commits-tbl) shows the top 30 scored trending packages with commits on Github and last half year's downloads. Package `V8` ranks first with `r trending_downloads$count[1]` download count and `r trending_downloads$commits[1]`. 

Figure \@ref(fig:commits-pattern) shows the scatterplot along with a smoothing line. In general, more commits, more downloads. What's more, most packages' commits are in the range of 100 to 400.

```{r commits-pattern, fig.align = 'center', fig.cap= "The package downloads of trending packages is increasing with the number of commits."}
trending_downloads %>%
  mutate(count = as.numeric(count)) %>%
  mutate(commits = as.numeric(commits)) %>%
  ggplot(aes(x = commits, y = count)) +
  geom_point() +
  geom_smooth(se = F) +
  scale_x_log10() +
  labs( y = 'Total download count',
          x = 'The number of commits',
    title = "Commits counts against download counts",
    subtitle = "of top 30 trending packages for last half year") +
    annotate("text",y= 70000,x= 500,label="In general, more commits, more downloads.",color="red") +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5))

```


## compare download counts with the number of updates for all 100 trending packages

Next, let's look at the relationship between the number of updates and the number of downloads.
In this part, our analysis object is still trending packages.

```{r function-updates-downloads}

# function used to get total updates and total downloads for a vector of packages
get_updates_downloads <- function(packages){
  
update_count <- function(packages){

  
  # get all the update dates and compute the number of updates of each package  
pkg_trending_updates <- get_arcvupdate_date(packages) %>%
  dplyr::group_by(package) %>%
  dplyr::count(package) %>%
  rename(`number of updates` = n)

}

update_counts <- update_count(packages) 

# get total downloads for each package 
total_downloads <- get_total_downloads(update_counts$package)

# join data
update_counts <- update_counts %>%
  as.data.frame() %>%
  left_join(total_downloads,by = "package")

return(update_counts)

}


```

Figure \@ref(fig:trend-updates) shows that the number of downloads increases with the increase of update times. And most packages are updated between 1 and 6 times.


```{r  trend-updates, fig.align = 'center', fig.cap=" The number of downloads increases with the increase of update times."}
pkg_trending_updates <- get_updates_downloads(pkg_trending$package) %>%
  mutate(score = as.numeric(count)) %>%
  mutate(updates = as.numeric(`number of updates`)) %>%
  arrange(desc(count))

pkg_trending_updates %>%
  ggplot(aes(x = `number of updates`, y = count)) +
  geom_point() +
  geom_smooth(se = F) +
  scale_x_log10() +
    labs( x = 'The number of updates',
          y = 'Total download count',
    title = "Updates counts against download counts",
    subtitle = "for 100 trending packages") +
  theme_minimal()  +
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5))
```


Also checking Table \@ref(tab:pct-lowupdates), we can know that the percentage of trending packages whose updates are less than average is 71, which means much more than half of the 100 trending packages do not tend to update very frequently. 


```{r  function-lowupdates}
# function used to compute packages lying in the low-updated range

compute_pct_lowupdated <- function(packages){
  
avg_updates <- mean(as.numeric(get_updates_downloads(packages)$`number of updates`))

pkg_trending_total <- length(packages)

pct_trending_updates <- get_updates_downloads(packages) %>%
  mutate(`number of updates` = as.numeric(`number of updates`))  %>%
  dplyr::filter(`number of updates` < avg_updates) %>%
  dplyr::summarise(`number of packages with low updates` = length(package)) %>%
  mutate(`percentage of packages with low updates` = (`number of packages with low updates`/pkg_trending_total)*100)

pct_trending_updates%>%
  kable(caption = "Percentage of trending packages whose updates are less than average") %>%
  kable_styling(bootstrap_options = c("hover", "striped"))

return(pct_trending_updates)

}

```

```{r pct-lowupdates}
# get the percentage of packages whose update counts is under the average
compute_pct_lowupdated(pkg_trending$package) 
  
```

It can be seen from Figure \@ref(fig:latestpublish) that most top 15 trending packages' latest publish date is after 2021, which indicates that popular packages tend to update by time to keep its activity. And this can also be explained from another aspect, that is, the a trending package refers to a package with a high download volume in a short period of recent time. We know that when a package is updated, its downloads will increase, so the latest update dates of trending packages are almost all the recent dates.

```{r function-latestupdate}
# function used to get the total downloads of a period of time and the latest release date
downloads_latest_release <- function(packages) {

# function used to get the latest release date from CRAN
latest_updates <- function(packages){
  
  latest_updates <- get_arcvupdate_date(packages) %>%
  group_by(package) %>%
  arrange(update, .by_group = TRUE) %>% #arrange within group
  top_n(1, update) # to get the latest release date, top_n() is used to select the highest value of a column within each group
  
}

latest_updates <- latest_updates(packages)

packages_vector <- latest_updates$package


# function used to get the total downloads of a period of time (date1 to date2) for several packages at the same time
get_total_downloads <- function(packages_vector){
  
total_downloads <- map(packages_vector, function(pkg){
  
  pkg <- cran_downloads(package = paste0(pkg), from = date1, to = date2) %>%
  summarise(package = package, count = sum(count)) %>%
  head(1)
  
})

 names(total_downloads) <- packages_vector

downloads <- unlist(total_downloads) %>% 
  enframe("package", "count") %>% 
  mutate(count = suppressWarnings(as.numeric(count)),
         # need to get rid of the numbers appended to pkg names
         package = str_extract(package, paste0(packages_vector, collapse="|")))%>%
         na.omit()
}

downloads <- get_total_downloads(packages_vector)
  
downloads_release_latest <- downloads %>%
  as.data.frame() %>%
  left_join(latest_updates,by = "package")

return(downloads_release_latest)
}
```


```{r  latestpublish,fig.align = 'center', fig.cap=" Most top 15 trending packages' latest publish date is after 2021."}

# before use the function 'downloads_latest_release()', please set the time range
date1 <- "2019-10-01"
date2 <- "2020-04-01"

pkg_trending1 <- pkg_trending %>%
  filter(!(package == "distro")) %>%
  filter(!(package == "decor")) %>%
  filter(!(package == "SeuratObject")) %>%
  filter(!(package == "bslib"))

pkg_trending_latest_publish <- unique(downloads_latest_release(pkg_trending1$package))

pkg_trending_latest_publish %>%
  ggplot(aes(update)) +
  geom_density() +
  labs( 
        x = 'Latest publish date',
    title = "Distribution of latest publish date",
    subtitle = "for trending packages") +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5))
```

Figure \@ref(fig:updates-perday) shows that with the increase of update interval, the number of downloads first increases and then decreases slightly. And most of the time intervals are between 45 and 450 days, which shows that their update frequency is not very high.

```{r updates-perday}

pkg_trending_earliest_publish <- unique(downloads_earliest_release(pkg_trending_latest_publish$package))

pkg_trending_daily_update <- left_join(pkg_trending_earliest_publish,pkg_trending_latest_publish,by = "package") %>%
  select(-count.y) %>%
  rename(count = count.x) %>%
  mutate(release_days = as.numeric(update.y - update.x)) 

pkg_trending_daily_update$release_days <- as.character(pkg_trending_daily_update$release_days)
pkg_trending_daily_update$release_days[pkg_trending_daily_update$release_days == "0"] <- "1"

pkg_trending_daily_update$release_days <- as.numeric(pkg_trending_daily_update$release_days)

pkg_trending_daily_update <- pkg_trending_daily_update %>%
left_join(get_updates_downloads(pkg_trending_daily_update$package))

pkg_trending_daily_update %>%
  mutate(days_peruodate = release_days/`number of updates`) %>%
  ggplot(aes(x = days_peruodate, y = count)) +
  geom_point(aes(colour = `number of updates`)) +
  geom_smooth(se = F) +
  labs( y = 'Total download counts',
          x = 'Days per update',
    title = "Daily update counts against the download counts",
    subtitle = "for trending packages") +
  scale_color_continuous(trans = 'log10') +
  scale_x_log10() +
  scale_y_sqrt() +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5))
```


In conclusion, it's not that the more updates the package has, the popular it will be. In the trending package, most of the packages whose updates are lower than the average occupy the majority. Therefore, we can also know that the total number of updates is not very important for the trending package. The important thing is to keep it updated.


## compare the package name length with download counts for trending packages

Here, I choose 500 random sample of all packages on CRAN to make the conclusion more representative.

```{r random-sample}
# generate random sample of the packages used to analyse name length
set.seed(2599)
x <- dplyr::pull(db,package)

pkg_random <- sample(x,500,replace = FALSE) %>%
  as.data.frame()

colnames(pkg_random)[1] <- 'package'
```

```{r  namelength-plot}
# use random sample
pkg_random1 <- pkg_random %>%
  mutate(length_name = nchar(package)) %>%
  mutate(count = get_total_downloads(package)$count)%>%
  rowwise()%>%
  mutate(length_name = as.numeric(length_name)) 

pkg_random1 <- pkg_random1 %>%
  arrange(desc(count)) 

  
pkg_random1 %>%
  group_by(length_name) %>%
  ggplot(aes(x = length_name, y = count)) +
  geom_point()+
  geom_smooth(se = F) +
  scale_y_sqrt() +
  scale_x_log10() +
  labs( y = 'Total download counts',
        x = 'The length of package names',
    title = "Name length against the download counts",
    subtitle = "for 500 random packages on CRAN") +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5))


```
We can see from Figure \@ref(fig:namelength-plot) that, in general, the influence of name length on download volume is not very obvious. But the names of packages with more than 100,000 downloads are between 5 and 9 characters long. And the most downloaded is package `r pkg_random1$package[1]` whose name length is `r pkg_random1$legnth_name[1]`, with `r pkg_random1$count[1]` download counts.

```{r namelength}
db_namelth <- db %>%
  select(package) %>%
  mutate(length_name = nchar(package)) 

`total average name length`  <- as.numeric(mean(db_namelth$length_name))
`pkg_trending_total` <- as.numeric(length(pkg_random$package))

pkg_random2 <- pkg_random1 %>%
  group_by(package) %>%
  dplyr::filter(length_name < `total average name length`) %>%
  ungroup() %>%
  dplyr::summarise(`number of short names` = length(package)) %>%
  mutate(`percentage of short names` = (`number of short names`/pkg_trending_total)*100)

compare_trending_namelth <- cbind(pkg_random2,`total average name length`)

```

Table \@ref(tab:pct-lngname) shows that the average name length of 500 random packages is `r compare_trending_namelth[[3]]`. And over half of the packages are more likely to have names shorter  than average. That means, to a certain extent, packages with shorter names are easier to get relatively higher downloads.

```{r pct-lngname}
compare_trending_namelth %>%
  kable(caption = "Percentage of trending packages whose updates are less than average") %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

```{r compute-ci}
# to get the 95% CI of the name length

# calculate the mean, sd and se
sample.mean <- mean(pkg_random1$length_name)
sample.n <- length(pkg_random1$length_name)
sample.sd <- sd(pkg_random1$length_name)
sample.se <- sample.sd/sqrt(sample.n)

# find t-score
alpha <- 0.05
degrees.freedom <- sample.n - 1
t.score <- qt(p=alpha/2, df=degrees.freedom,lower.tail=F)

margin.error <- t.score * sample.se

# get the 95% CI
lower.bound <- sample.mean - margin.error
upper.bound <- sample.mean + margin.error

namelth_CI <- cbind(lower.bound,upper.bound)

```

Table \@ref(tab:pct-lngname) shows the 95% confidence interval of name length for trending packages. We could know that the 95% suitable name length is between `r namelth_CI[[1]]` and `r namelth_CI[[2]]` characters.

```{r namelth-ci}
namelth_CI %>%
  kable(caption = "95% Confidence Interval of name length for random packages") %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

## compare download counts with alphabetical order of name

From the perspective of package name, in addition to the length, does the alphabetic order of the first letter also affect the download volume? To answer this question, I grouped the packages in 26-letter order, calculated the average downloads of each group, and then compared them.

```{r random-sample1}
# generate random sample of the packages used to analyze name alphabetic order
set.seed(2599)
x <- dplyr::pull(db,package)

# expand the sample size
pkg_random_new <- sample(x,1000,replace = FALSE) %>%
  as.data.frame()

colnames(pkg_random_new)[1] <- 'package'

pkg_random_new1 <- pkg_random_new %>%
  mutate(length_name = nchar(package)) %>%
  mutate(count = get_total_downloads(package)$count)%>%
  rowwise()%>%
  mutate(length_name = as.numeric(length_name)) 
```

```{r alpha-function}
get_downloads_alphabetic <- function(df){
  
  
  avg_downloads_alphabetic <- function(df,letter){
  
  avg_downloads <- df %>%
  select(-length_name) %>%
  filter(str_detect(package, paste0(letter)))%>%
  ungroup() %>%
  summarise(avg_downloads = mean(count))

  return(avg_downloads)
  
  }
  
 avg_downloads_a <- avg_downloads_alphabetic(df,"^a|^A")
 avg_downloads_b <- avg_downloads_alphabetic(df,"^b|^B")
 avg_downloads_c <- avg_downloads_alphabetic(df,"^c|^C")
 avg_downloads_d <- avg_downloads_alphabetic(df,"^d|^D")
 avg_downloads_e <- avg_downloads_alphabetic(df,"^e|^E")
 avg_downloads_f <- avg_downloads_alphabetic(df,"^f|^F")
 avg_downloads_g <- avg_downloads_alphabetic(df,"^g|^G")
 avg_downloads_h <- avg_downloads_alphabetic(df,"^h|^H")
 avg_downloads_i <- avg_downloads_alphabetic(df,"^i|^I")
 avg_downloads_j <- avg_downloads_alphabetic(df,"^j|^J")
 avg_downloads_k <- avg_downloads_alphabetic(df,"^k|^K")
 avg_downloads_l <- avg_downloads_alphabetic(df,"^l|^L")
 avg_downloads_m <- avg_downloads_alphabetic(df,"^m|^M")
 avg_downloads_n <- avg_downloads_alphabetic(df,"^n|^N")
 avg_downloads_o <- avg_downloads_alphabetic(df,"^o|^O")
 avg_downloads_p <- avg_downloads_alphabetic(df,"^p|^P")
 avg_downloads_q <- avg_downloads_alphabetic(df,"^q|^Q")
 avg_downloads_r <- avg_downloads_alphabetic(df,"^r|^R")
 avg_downloads_s <- avg_downloads_alphabetic(df,"^s|^S")
 avg_downloads_t <- avg_downloads_alphabetic(df,"^t|^T")
 avg_downloads_u <- avg_downloads_alphabetic(df,"^u|^U")
 avg_downloads_v <- avg_downloads_alphabetic(df,"^v|^V")
 avg_downloads_w <- avg_downloads_alphabetic(df,"^w|^W")
 avg_downloads_x <- avg_downloads_alphabetic(df,"^x|^X")
 avg_downloads_y <- avg_downloads_alphabetic(df,"^y|^Y")
 avg_downloads_z <- avg_downloads_alphabetic(df,"^z|^Z")
 
 avg_downloads <- rbind(avg_downloads_a,avg_downloads_b,avg_downloads_c,avg_downloads_d,avg_downloads_e,avg_downloads_f,avg_downloads_g,avg_downloads_h,avg_downloads_i,avg_downloads_j,avg_downloads_k,avg_downloads_l,avg_downloads_m,avg_downloads_n,avg_downloads_o,avg_downloads_p,avg_downloads_q,avg_downloads_r,avg_downloads_s,avg_downloads_t,avg_downloads_u,avg_downloads_v,avg_downloads_w,avg_downloads_x,avg_downloads_y,avg_downloads_z)
 
`alphabetic group` <- LETTERS[1:26] %>%
  as.data.frame()

colnames(`alphabetic group`)[1] <- 'alphabetic group'

avg_downloads <- cbind(avg_downloads,`alphabetic group`)

return(avg_downloads)
  
}

alphabetic_downloads <- get_downloads_alphabetic(pkg_random_new1)

```

From Figure \@ref(fig:ahlpha-downloads) we could see that 
```{r ahlpha-downloads}

alphabetic_downloads %>%
  ggplot(aes(x = `alphabetic group`,y = avg_downloads)) +
  geom_point() +
  labs( y = 'Total download counts',
    title = "Mean download counts against different alphabetic group",
    subtitle = "for 500 random packages") +
  scale_y_log10() +
  theme_minimal()  +
  theme(panel.grid.major = element_blank()) +
  theme(
  axis.text=element_text(size=10),
  axis.title=element_text(size=12,face="bold"),
  plot.title = element_text(h = 0.5),
  plot.subtitle = element_text(h = 0.5),
  axis.title.x = element_blank())
```

