# Introduction {#intro}

R is a widely used programming language, and also a free software environment for statistical calculation and mapping analysis. R is popular among statisticians and data analysts, with being widely used in statistical software development and data analysis. In the process of using R, we need to extend its functions with the help of R packages, so R packages have become an indispensable part when people use R to work and study. R packages can be downloaded from CRAN, a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R. It is precisely because R package is so important and basic for users of R, we will be quite concerned about everything about package. On the one hand, Some users of R are also developers of R packages, therefore, these people may be concerned about the download amount and popularity of their packages. For ordinary users of R, when they want to choose a suitable package for a certain job, for example, they want to do Bayesian analysis, and there are many packages with this function, then they would want to know which packages are the most popular or practical. Based on this, the purpose of this project is to analyze and explore the packages download on CRAN, and try to provide one or more methods to modify the download amount of packages or help users and developers better understand the download amount pattern.

As mentioned above, we often care about the popularity of R packages, then a question would come naturally: how to measure what is popular and what is unpopular? For example, if a package has been downloaded 10000 times, can we infer that it is popular? The answer is obviously no, because popularity is a relative concept, which needs to be reflected in comparison. In order to answer this question, some scholars have provided methods for reference, which will be introduced in the following part. What's more, let's extend it to this question. If a package has 10000 downloads, and it ranks in the top 10 among all packages of the same type, does that necessarily reflect its true popularity? The answer is obviously no as well, because in the 10000 downloads, there may be reloaded counts, share download counts and download counts from dependent packages. We usually think that the real popularity of a package should be the sum of the single downloads of different users, which can reflect the user coverage of this package. And this problem was also solved by a scholar that will be mentioned later. And so on, there are many thinking and analysis dimensions about CRAN analysis, which will be an interesting and practical exploration.

Next, I would like to introduce some terms involved in this project.

- R language : R is a language and environment for statistical computing and graphics which can be extended easily via packages and provide an Open Source route to participation in statistical methodology. It is available as Free Software under the term of the Free Software Foundation’s GNU General Public License[@gnu].

- R Studio : It is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management.

- R Packages : They are collections of functions and data sets developed by the community. They increase the power of R by improving existing base R functionalities, or by adding new ones.

- CRAN : It is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R.

- CRAN mirror : It is a website containing differently located servers, which aims to facilitate people from different regions and countries to access CRAN more smoothly and quickly. And each server is called a mirror.

- API : It is the abbreviation of Application Programming Interface, which is a software intermediary that allows two applications to talk to each other. 


## rtrends

And then we come to the related literatures, which are as followed:

- [`rtrends`](https://cran.r-project.org/web/packages/rtrends/rtrends.pdf)
This is a package used for simple analysis of download logs from the CRAN RStudio Mirror, which contains one dataset and five functions. It's mainly functions are:

(1) abstract all CRAN download logs for a specific date
(2) abstract CRAN download logs for a specific package
(3) abstract CRAN download logs for a several package in a range of dates
(4) merge CRAN download logs with county names
(5) provide sample formatted CRAN logs

- [`packageRank`](https://github.com/lindbrook/packageRank).
It is also a package that relies on package `cranlog` and extends its functionality.It can publish the total download logs from CRAN with a more user-friendly interface and providing generic R `plot()` methods to make visualization easy. Also, many package creators are very concerned about the popularity of their packages, and this package `packageRank` can show the percentage of packages with less downloads. Furthermore, when we count the download logs, the exact thing we want is the number of times the package has been completely downloaded. In fact, we often encounter some wrongly sized download records, that is to say, users only download a part of the normal sized package. One is called "medium", the other is "small", which exists either as a part of pair with a full download or one of triplet with a "medium" and a full downloads. In order to deal with this, the creator filters the "small" entries that are less 1000 bytes and use triplet-specific filter to do with the "medium" entries.

Generally speaking, the function of this package is divided into two directions, one is to calculate the rank percentile, the other is to filter invalid package downloads. In addition, a series of visualization methods are provided. Here, I will mainly explain how the above two functions are brought about.

(1) Computing the rank percentile

This package computes rank percentile for a single package's one-day download. First of all, find out the sum of the downloads of all packages whose daily downloads are smaller than that of this package, and record it as A, and get the downloads of all packages from Bioconductor on this day, record it as B, then divide A by B. We would get the rank percentage of this package in this way.

(2) Filtering invalid downloads

There are five types filtering functions inside this package:

`ip.filter` : it is used to remove campaigns of those IP address that has downloaded the same package for too many times. And the 'to many times' is set to 10. And the statistical method used here is k-means clustering.

`triplet.filter` : reduce the triplets to a single observation... (to be added)

`small.filter` : it is used to remove entries smaller than 1000 bytes. Why 1000 bytes?  Because this is even smaller than the smallest-sizes package in CRAN named 'source.gist'. In other words, packages smaller than this size are "small" packages that should be removed. 

`sequence.filter` : removes logs that is of past versions. When people download the historical version of a package, they may be more interested in CRAN than in the package itself.

`size.filter` : removes entries smaller than a package’s binary or source file. (to be added...)



- [`cranlogs`](https://github.com/r-hub/cranlogs) - to download the summary download data. 
It is a R package used to publish the total download logs from CRAN mirror in last day, last week or even a specific time range, for one package or several packages. And it can used to figure out the top downloaded packages in a time.

- [`adjustedcranlogs`](https://github.com/tylermorganwall/adjustedcranlogs). 
We already know that the main function of `cranlogs` is to show the total number of download logs, but in practice, so the statistics of that will face the following problems: including the number of shared download logs, the same user downloads the same package again for some reason, and when a package is updated, the number of download logs will surge. Due to that, `adjustedcranlogs` is a wrapper around the `cranlogs` package that removes these two types of download logs. Therefore, using the data processed by this package to plot, we will find that the fluctuation of the download logs will be smaller.
The only function inside this package is `adj_cran_downloads()`, which returns a data frame showing the adjusted downloads, adjusted total downloads, shared minimum downloads, and package update information.

The specific method is as follows:
This package mainly removes two types of downloads, one is the spike in downloads due to automatic re-downloads, the other is CRAN mirrors associated with a package update. First, it will find out the minimum download amount of a package, and then subtract the minimum download amount from the original download amount obtained through `cranlogs::cran_downloads` function to get an adjusted download amount. And in order to remove the spike, it uses two discriminant process: first, it determines whether a certain day is an update day, if so, it has value TRUE, if not, it has value FALSE. Then it determines that if two consecutive days are update days for the same package, if so, the median of the adjusted load per day of this package would be used as the daily download amount of each of these two days. 



- [`cran.stats`](https://github.com/arunsrinivasan/cran.stats)
This package can also be used to get the total number of download logs first, but it is different from the previous package in that it gets seasonal data, such as annual, monthly and weekly. Besides, packages can have dependencies with each other, which means when a package is downloaded, its dependent package is also downloaded. But this will cause a problem, that is, when users download a package with its dependent package also downloaded, the download logs may not reflect the actual popularity of that dependent package. Therefore, another function of this package can solve this problem well by identifying and subtracting the downloads due to it's dependent packages. Also, there is one function used to plot direct downloads and downloads due to dependencies separately.

- [`dlstats`](https://github.com/GuangchuangYu/dlstats)


- [`pkgsearch`](https://github.com/r-hub/pkgsearch/)
This is a package used to query packages in multiple dimensions. First, users can search by the usage of the package, and `pkgsearch` will return the results with popular packages before less frequently used ones. Or there is a `CRAN package search` addin in menu, with which users can search packages by clicking easily. And it can publish the version history of certain package or display the recent trending packages in detail. Besides, it can provide the latest releases or archivals. Moreover, the search server uses the stems of the words in the indexed metadata, and the search phrase. In this way, the deceleration result will not be affected by the grammar of spelling and tense, which increases the fault tolerance rate and become more user-friendly. At this point, there is also a functional extension, that is, the search engine prefers matching whole phrases over single words.This means that it will consider more about the meaning of the entire search term than match a word, which makes the results more accurate. For example, the search phrase “permutation test” will rank coin higher than testthat, even though testthat is a much better result for the single word “test”. And it uses weighted scoring to show the ranking of the results, which includes reverse dependencies, matching degree of title and description and the number of downloads. Finally, it also provides ASCII folding for easy retrieval. In general, this is a comprehensive, practical and interesting search package.

- [`Visualize.CRAN.Downloads`](https://cran.r-project.org/web/packages/Visualize.CRAN.Downloads/vignettes/Visualize.CRAN.Downloads.html)
This package provides a variety of methods and different types of presentation to visualize the downloads of packages, including static plots, interactive plots and comparison plot. These visualizations mainly focus on the single or comparative study of package downloads in a certain period of time. It includes the change of daily download volume with time, the change of cumulative total download volume, the fluctuation of average download volume and download volume within the standard deviation. In addition, it also provides many function options for splitting or combining figures to make visualization as comprehensive and flexible as possible.


## Helpful tips

You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods).

Figures and tables with captions will be placed in `figure` and `table` environments, respectively.

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```

Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab).

```{r nice-tab, tidy=FALSE}
knitr::kable(
  head(iris, 20), caption = 'Here is a nice table!',
  booktabs = TRUE
)
```


You can write citations, too. For example, we are using the **bookdown** package [@R-bookdown] in this sample book, which was built on top of R Markdown and **knitr** [@xie2015].
